diff --git a/fb/fbmmx.c b/fb/fbmmx.c
index 21eb5f3..fd12844 100644
--- a/fb/fbmmx.c
+++ b/fb/fbmmx.c
@@ -1,5 +1,5 @@
 /*
- * Copyright © 2004 Red Hat, Inc.
+ * Copyright © 2004, 2005 Red Hat, Inc.
  * Copyright © 2004 Nicholas Miell
  * Copyright © 2005 Trolltech AS
  *
@@ -56,21 +56,272 @@
 #define CHECKPOINT()
 #endif
 
+/* Notes about writing mmx code
+ *
+ * give memory operands as the second operand. If you give it as the
+ * first, gcc will first load it into a register, then use that
+ * register
+ *
+ *   ie. use
+ *
+ *         _mm_mullo_pi16 (x, mmx_constant);
+ *
+ *   not
+ *
+ *         _mm_mullo_pi16 (mmx_constant, x);
+ *
+ * Also try to minimize dependencies. i.e. when you need a value, try
+ * to calculate it from a value that was calculated as early as
+ * possible.
+ */
+
+/* --------------- MMX primitivess ------------------------------------ */
+
+typedef unsigned long long ullong;
+
+typedef struct
+{
+    ullong mmx_4x00ff;
+    ullong mmx_4x0080;
+    ullong mmx_565_rgb;
+    ullong mmx_565_unpack_multiplier;
+    ullong mmx_565_r;
+    ullong mmx_565_g;
+    ullong mmx_565_b;
+    ullong mmx_mask_0;
+    ullong mmx_mask_1;
+    ullong mmx_mask_2;
+    ullong mmx_mask_3;
+    ullong mmx_full_alpha;
+    ullong mmx_ffff0000ffff0000;
+    ullong mmx_0000ffff00000000;
+    ullong mmx_000000000000ffff;
+} MMXData;
+
+static const MMXData c =
+{
+    .mmx_4x00ff =			0x00ff00ff00ff00ffULL,
+    .mmx_4x0080 =			0x0080008000800080ULL,
+    .mmx_565_rgb =			0x000001f0003f001fULL,
+    .mmx_565_r =			0x000000f800000000ULL,
+    .mmx_565_g =			0x0000000000fc0000ULL,
+    .mmx_565_b =			0x00000000000000f8ULL,
+    .mmx_mask_0 =			0xffffffffffff0000ULL,
+    .mmx_mask_1 =			0xffffffff0000ffffULL,
+    .mmx_mask_2 =			0xffff0000ffffffffULL,
+    .mmx_mask_3 =			0x0000ffffffffffffULL,
+    .mmx_full_alpha =			0x00ff000000000000ULL,
+    .mmx_565_unpack_multiplier =	0x0000008404100840ULL,
+    .mmx_ffff0000ffff0000 =		0xffff0000ffff0000ULL,
+    .mmx_0000ffff00000000 =		0x0000ffff00000000ULL,
+    .mmx_000000000000ffff =		0x000000000000ffffULL,
+};
+
+#define MC(x) ((__m64) c.mmx_##x)
+
+static __inline__ __m64
+shift (__m64 v, int s)
+{
+    if (s > 0)
+	return _mm_slli_si64 (v, s);
+    else if (s < 0)
+	return _mm_srli_si64 (v, -s);
+    else
+	return v;
+}
+
+static __inline__ __m64
+negate (__m64 mask)
+{
+    return _mm_xor_si64 (mask, MC(4x00ff));
+}
+
+static __inline__ __m64
+pix_multiply (__m64 a, __m64 b)
+{
+    __m64 res;
+    
+    res = _mm_mullo_pi16 (a, b);
+    res = _mm_adds_pu16 (res, _mm_srli_pi16 (res, 8));
+    res = _mm_adds_pu16 (res, MC(4x0080));
+    res = _mm_srli_pi16 (res, 8);
+    
+    return res;
+}
+
+static __inline__ __m64
+pix_add (__m64 a, __m64 b)
+{
+    return  _mm_adds_pu8 (a, b);
+}
+
+static __inline__ __m64
+expand_alpha (__m64 pixel)
+{
+    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(3, 3, 3, 3));
+}
+
+static __inline__ __m64
+expand_alpha_rev (__m64 pixel)
+{
+    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(0, 0, 0, 0));
+}    
+
+static __inline__ __m64
+invert_colors (__m64 pixel)
+{
+    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(3, 0, 1, 2));
+}
+
+static __inline__ __m64
+over (__m64 src, __m64 srca, __m64 dest)
+{
+    return  _mm_adds_pu8 (src, pix_multiply(dest, negate(srca)));
+}
+
+static __inline__ __m64
+over_rev_non_pre (__m64 src, __m64 dest)
+{
+    __m64 srca = expand_alpha (src);
+    __m64 srcfaaa = _mm_or_si64 (srca, MC(full_alpha));
+    
+    return over(pix_multiply(invert_colors(src), srcfaaa), srca, dest);
+}
+
+static __inline__ __m64
+in (__m64 src,
+    __m64 mask)
+{
+    return pix_multiply (src, mask);
+}
+
+static __inline__ __m64
+in_over (__m64 src,
+	 __m64 srca,
+	 __m64 mask,
+	 __m64 dest)
+{
+    return over(in(src, mask), pix_multiply(srca, mask), dest);
+}
+
+static __inline__ __m64
+load8888 (CARD32 v)
+{
+    return _mm_unpacklo_pi8 (_mm_cvtsi32_si64 (v), _mm_setzero_si64());
+}
+
+static __inline__ __m64
+pack8888 (__m64 lo, __m64 hi)
+{
+    return _mm_packs_pu16 (lo, hi);
+}
+
+static __inline__ CARD32
+store8888 (__m64 v)
+{
+    return _mm_cvtsi64_si32(pack8888(v, _mm_setzero_si64()));
+}
+
+/* Expand 16 bits positioned at @pos (0-3) of a mmx register into
+ *
+ *    00RR00GG00BB
+ * 
+ * --- Expanding 565 in the low word ---
+ * 
+ * m = (m << (32 - 3)) | (m << (16 - 5)) | m;
+ * m = m & (01f0003f001f);
+ * m = m * (008404100840);
+ * m = m >> 8;
+ * 
+ * Note the trick here - the top word is shifted by another nibble to
+ * avoid it bumping into the middle word
+ */
+static __inline__ __m64
+expand565 (__m64 pixel, int pos)
+{
+    __m64 p = pixel;
+    __m64 t1, t2;
+    
+    /* move pixel to low 16 bit and zero the rest */
+    p = shift (shift (p, (3 - pos) * 16), -48); 
+    
+    t1 = shift (p, 36 - 11);
+    t2 = shift (p, 16 - 5);
+    
+    p = _mm_or_si64 (t1, p);
+    p = _mm_or_si64 (t2, p);
+    p = _mm_and_si64 (p, MC(565_rgb));
+    
+    pixel = _mm_mullo_pi16 (p, MC(565_unpack_multiplier));
+    return _mm_srli_pi16 (pixel, 8);
+}
+
+static __inline__ __m64
+expand8888 (__m64 in, int pos)
+{
+    if (pos == 0)
+	return _mm_unpacklo_pi8 (in, _mm_setzero_si64());
+    else
+	return _mm_unpackhi_pi8 (in, _mm_setzero_si64());
+}
+
+static __inline__ __m64
+pack565 (__m64 pixel, __m64 target, int pos)
+{
+    __m64 p = pixel;
+    __m64 t = target;
+    __m64 r, g, b;
+    
+    r = _mm_and_si64 (p, MC(565_r));
+    g = _mm_and_si64 (p, MC(565_g));
+    b = _mm_and_si64 (p, MC(565_b));
+    
+    r = shift (r, - (32 - 8) + pos * 16);
+    g = shift (g, - (16 - 3) + pos * 16);
+    b = shift (b, - (0  + 3) + pos * 16);
+    
+    if (pos == 0)
+	t = _mm_and_si64 (t, MC(mask_0));
+    else if (pos == 1)
+	t = _mm_and_si64 (t, MC(mask_1));
+    else if (pos == 2)
+	t = _mm_and_si64 (t, MC(mask_2));
+    else if (pos == 3)
+	t = _mm_and_si64 (t, MC(mask_3));
+    
+    p = _mm_or_si64 (r, t);
+    p = _mm_or_si64 (g, p);
+    
+    return _mm_or_si64 (b, p);
+}
+
+static __inline__ __m64
+pix_add_mul (__m64 x, __m64 a, __m64 y, __m64 b)
+{
+    x = _mm_mullo_pi16 (x, a);                  
+    y = _mm_mullo_pi16 (y, b);                  
+    x = _mm_srli_pi16(x, 1);                    
+    y = _mm_srli_pi16(y, 1);                    
+    x = _mm_adds_pu16 (x, y);                    
+    x = _mm_adds_pu16 (x, _mm_srli_pi16 (x, 8)); 
+    x = _mm_adds_pu16 (x, MC(4x0080));
+    x = _mm_srli_pi16 (x, 7);
+
+    return x;
+}
+
 /* --------------- MMX code patch for fbcompose.c --------------------- */
 
 static FASTCALL void
 mmxCombineMaskU (CARD32 *src, const CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    
     const CARD32 *end = mask + width;
     while (mask < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        a = MmxAlpha(a);
-        MmxMul(s, a);
-        *src = MmxFrom(s);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        a = expand_alpha(a);
+        s = pix_multiply(s, a);
+        *src = store8888(s);
         ++src;
         ++mask;
     }
@@ -81,20 +332,13 @@ mmxCombineMaskU (CARD32 *src, const CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineOverU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
-        __m64 x, y, a;
-        x = MmxTo(*src);
-        y = MmxTo(*dest);
-        a = MmxAlpha(x);
-        a = MmxNegate(a);
-        MmxMulAdd(y, a, x);
-        *dest = MmxFrom(y);
+        __m64 s, sa;
+	s = load8888(*src);
+	sa = expand_alpha(s);
+	*dest = store8888(over(s, sa, load8888(*dest)));
         ++dest;
         ++src;
     }
@@ -104,20 +348,13 @@ mmxCombineOverU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineOverReverseU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
-        __m64 x, y, a;
-        x = MmxTo(*dest);
-        y = MmxTo(*src);
-        a = MmxAlpha(x);
-        a = MmxNegate(a);
-        MmxMulAdd(y, a, x);
-        *dest = MmxFrom(y);
+	__m64 d, da;
+	d = load8888(*dest);
+	da = expand_alpha(d);
+	*dest = store8888(over (d, da, load8888(*src)));
         ++dest;
         ++src;
     }
@@ -127,18 +364,15 @@ mmxCombineOverReverseU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineInU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 x, a;
-        x = MmxTo(*src);
-        a = MmxTo(*dest);
-        a = MmxAlpha(a);
-        MmxMul(x, a);
-        *dest = MmxFrom(x);
+        x = load8888(*src);
+        a = load8888(*dest);
+        a = expand_alpha(a);
+        x = pix_multiply(x, a);
+        *dest = store8888(x);
         ++dest;
         ++src;
     }
@@ -148,18 +382,15 @@ mmxCombineInU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineInReverseU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 x, a;
-        x = MmxTo(*dest);
-        a = MmxTo(*src);
-        a = MmxAlpha(a);
-        MmxMul(x, a);
-        *dest = MmxFrom(x);
+        x = load8888(*dest);
+        a = load8888(*src);
+        a = expand_alpha(a);
+        x = pix_multiply(x, a);
+        *dest = store8888(x);
         ++dest;
         ++src;
     }
@@ -169,20 +400,16 @@ mmxCombineInReverseU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineOutU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 x, a;
-        x = MmxTo(*src);
-        a = MmxTo(*dest);
-        a = MmxAlpha(a);
-        a = MmxNegate(a);
-        MmxMul(x, a);
-        *dest = MmxFrom(x);
+        x = load8888(*src);
+        a = load8888(*dest);
+        a = expand_alpha(a);
+        a = negate(a);
+        x = pix_multiply(x, a);
+        *dest = store8888(x);
         ++dest;
         ++src;
     }
@@ -192,20 +419,16 @@ mmxCombineOutU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineOutReverseU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 x, a;
-        x = MmxTo(*dest);
-        a = MmxTo(*src);
-        a = MmxAlpha(a);
-        a = MmxNegate(a);
-        MmxMul(x, a);
-        *dest = MmxFrom(x);
+        x = load8888(*dest);
+        a = load8888(*src);
+        a = expand_alpha(a);
+        a = negate(a);
+        x = pix_multiply(x, a);
+        *dest = store8888(x);
         ++dest;
         ++src;
     }
@@ -215,21 +438,17 @@ mmxCombineOutReverseU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineAtopU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 s, da, d, sia;
-        s = MmxTo(*src);
-        d = MmxTo(*dest);
-        sia = MmxAlpha(s);
-        sia = MmxNegate(sia);
-        da = MmxAlpha(d);
-        MmxAddMul(s, da, d, sia);
-        *dest = MmxFrom(s);
+        s = load8888(*src);
+        d = load8888(*dest);
+        sia = expand_alpha(s);
+        sia = negate(sia);
+        da = expand_alpha(d);
+        s = pix_add_mul (s, da, d, sia);
+        *dest = store8888(s);
         ++dest;
         ++src;
     }
@@ -239,23 +458,19 @@ mmxCombineAtopU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineAtopReverseU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end;
 
     end = dest + width;
 
     while (dest < end) {
         __m64 s, dia, d, sa;
-        s = MmxTo(*src);
-        d = MmxTo(*dest);
-        sa = MmxAlpha(s);
-        dia = MmxAlpha(d);
-        dia = MmxNegate(dia);
-        MmxAddMul(s, dia, d, sa);
-        *dest = MmxFrom(s);
+        s = load8888(*src);
+        d = load8888(*dest);
+        sa = expand_alpha(s);
+        dia = expand_alpha(d);
+        dia = negate(dia);
+	s = pix_add_mul (s, dia, d, sa);
+        *dest = store8888(s);
         ++dest;
         ++src;
     }
@@ -265,22 +480,18 @@ mmxCombineAtopReverseU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineXorU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-
     const CARD32 *end = dest + width;
 
     while (dest < end) {
         __m64 s, dia, d, sia;
-        s = MmxTo(*src);
-        d = MmxTo(*dest);
-        sia = MmxAlpha(s);
-        dia = MmxAlpha(d);
-        sia = MmxNegate(sia);
-        dia = MmxNegate(dia);
-        MmxAddMul(s, dia, d, sia);
-        *dest = MmxFrom(s);
+        s = load8888(*src);
+        d = load8888(*dest);
+        sia = expand_alpha(s);
+        dia = expand_alpha(d);
+        sia = negate(sia);
+        dia = negate(dia);
+	s = pix_add_mul (s, dia, d, sia);
+        *dest = store8888(s);
         ++dest;
         ++src;
     }
@@ -290,15 +501,13 @@ mmxCombineXorU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineAddU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-
     const CARD32 *end = dest + width;
     while (dest < end) {
         __m64 s, d;
-        s = MmxTo(*src);
-        d = MmxTo(*dest);
-        s = MmxAdd(s, d);
-        *dest = MmxFrom(s);
+        s = load8888(*src);
+        d = load8888(*dest);
+        s = pix_add(s, d);
+        *dest = store8888(s);
         ++dest;
         ++src;
     }
@@ -308,25 +517,22 @@ mmxCombineAddU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineSaturateU (CARD32 *dest, const CARD32 *src, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-
     const CARD32 *end = dest + width;
     while (dest < end) {
         CARD32 s = *src;
         CARD32 d = *dest;
-        __m64 ms = MmxTo(s);
-        __m64 md = MmxTo(d);
+        __m64 ms = load8888(s);
+        __m64 md = load8888(d);
         CARD32 sa = s >> 24;
         CARD32 da = ~d >> 24;
 
         if (sa > da) {
-            __m64 msa = MmxTo(FbIntDiv(da, sa));
-            msa = MmxAlpha(msa);
-            MmxMul(ms, msa);
+            __m64 msa = load8888(FbIntDiv(da, sa));
+            msa = expand_alpha(msa);
+            ms = pix_multiply(ms, msa);
         }
-        MmxAdd(md, ms);
-        *dest = MmxFrom(md);
+        md = pix_add(md, ms);
+        *dest = store8888(md);
         ++src;
         ++dest;
     }
@@ -337,15 +543,12 @@ mmxCombineSaturateU (CARD32 *dest, const CARD32 *src, int width)
 static FASTCALL void
 mmxCombineSrcC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        MmxMul(s, a);
-        *dest = MmxFrom(s);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        s = pix_multiply(s, a);
+        *dest = store8888(s);
         ++src;
         ++mask;
         ++dest;
@@ -356,21 +559,15 @@ mmxCombineSrcC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineOverC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 sa = MmxAlpha(s);
-        MmxMul(s, a);
-        MmxMul(a, sa);
-        a = MmxNegate(a);
-        MmxMulAdd(d, a, s);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 sa = expand_alpha(s);
+	
+	*dest = store8888(in_over (s, sa, a, d));
+	
         ++src;
         ++dest;
         ++mask;
@@ -381,20 +578,15 @@ mmxCombineOverC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineOverReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        da = MmxNegate(da);
-        MmxMul(s, a);
-        MmxMulAdd(s, da, d);
-        *dest = MmxFrom(s);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+
+	*dest = store8888(over (d, da, in (s, a)));
+	
         ++src;
         ++dest;
         ++mask;
@@ -406,18 +598,15 @@ mmxCombineOverReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineInC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        MmxMul(s, a);
-        MmxMul(s, da);
-        *dest = MmxFrom(s);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+        s = pix_multiply(s, a);
+        s = pix_multiply(s, da);
+        *dest = store8888(s);
         ++src;
         ++dest;
         ++mask;
@@ -428,18 +617,15 @@ mmxCombineInC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineInReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 sa = MmxAlpha(s);
-        MmxMul(a, sa);
-        MmxMul(d, a);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 sa = expand_alpha(s);
+        a = pix_multiply(a, sa);
+        d = pix_multiply(d, a);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -450,20 +636,16 @@ mmxCombineInReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineOutC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        da = MmxNegate(da);
-        MmxMul(s, a);
-        MmxMul(s, da);
-        *dest = MmxFrom(s);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+        da = negate(da);
+        s = pix_multiply(s, a);
+        s = pix_multiply(s, da);
+        *dest = store8888(s);
         ++src;
         ++dest;
         ++mask;
@@ -474,20 +656,16 @@ mmxCombineOutC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineOutReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 sa = MmxAlpha(s);
-        MmxMul(a, sa);
-        a = MmxNegate(a);
-        MmxMul(d, a);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 sa = expand_alpha(s);
+        a = pix_multiply(a, sa);
+        a = negate(a);
+        d = pix_multiply(d, a);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -498,22 +676,18 @@ mmxCombineOutReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineAtopC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        __m64 sa = MmxAlpha(s); 
-        MmxMul(s, a);
-        MmxMul(a, sa);
-        a = MmxNegate(a);
-        MmxAddMul(d, a, s, da);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+        __m64 sa = expand_alpha(s); 
+        s = pix_multiply(s, a);
+        a = pix_multiply(a, sa);
+        a = negate(a);
+	d = pix_add_mul (d, a, s, da);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -524,22 +698,18 @@ mmxCombineAtopC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineAtopReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        __m64 sa = MmxAlpha(s)
-        MmxMul(s, a);
-        MmxMul(a, sa);
-        da = MmxNegate(da);
-        MmxAddMul(d, a, s, da);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+        __m64 sa = expand_alpha(s);
+        s = pix_multiply(s, a);
+        a = pix_multiply(a, sa);
+        da = negate(da);
+	d = pix_add_mul (d, a, s, da);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -550,23 +720,19 @@ mmxCombineAtopReverseC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineXorC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    const __m64 mmx_4x00ff = (__m64) 0x00ff00ff00ff00ffULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        __m64 da = MmxAlpha(d);
-        __m64 sa = MmxAlpha(s);
-        MmxMul(s, a);
-        MmxMul(a, sa);
-        da = MmxNegate(da);
-        a = MmxNegate(a);
-        MmxAddMul(d, a, s, da);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        __m64 da = expand_alpha(d);
+        __m64 sa = expand_alpha(s);
+        s = pix_multiply(s, a);
+        a = pix_multiply(a, sa);
+        da = negate(da);
+        a = negate(a);
+	d = pix_add_mul (d, a, s, da);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -577,17 +743,14 @@ mmxCombineXorC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 static FASTCALL void
 mmxCombineAddC (CARD32 *dest, CARD32 *src, CARD32 *mask, int width)
 {
-    const __m64 mmx_0 = _mm_setzero_si64();
-    const __m64 mmx_4x0080 = (__m64) 0x0080008000800080ULL;
-    
     const CARD32 *end = src + width;
     while (src < end) {
-        __m64 a = MmxTo(*mask);
-        __m64 s = MmxTo(*src);
-        __m64 d = MmxTo(*dest);
-        MmxMul(s, a);
-        d = MmxAdd(s, d);
-        *dest = MmxFrom(d);
+        __m64 a = load8888(*mask);
+        __m64 s = load8888(*src);
+        __m64 d = load8888(*dest);
+        s = pix_multiply(s, a);
+        d = pix_add(s, d);
+        *dest = store8888(d);
         ++src;
         ++dest;
         ++mask;
@@ -632,231 +795,6 @@ void fbComposeSetupMMX(void)
 
 /* ------------------ MMX code paths called from fbpict.c ----------------------- */
 
-typedef struct
-{
-    ullong mmx_4x00ff;
-    ullong mmx_4x0080;
-    ullong mmx_565_rgb;
-    ullong mmx_565_unpack_multiplier;
-    ullong mmx_565_r;
-    ullong mmx_565_g;
-    ullong mmx_565_b;
-    ullong mmx_mask_0;
-    ullong mmx_mask_1;
-    ullong mmx_mask_2;
-    ullong mmx_mask_3;
-    ullong mmx_full_alpha;
-    ullong mmx_ffff0000ffff0000;
-    ullong mmx_0000ffff00000000;
-    ullong mmx_000000000000ffff;
-} MMXData;
-
-static const MMXData c =
-{
-    .mmx_4x00ff =			0x00ff00ff00ff00ffULL,
-    .mmx_4x0080 =			0x0080008000800080ULL,
-    .mmx_565_rgb =			0x000001f0003f001fULL,
-    .mmx_565_r =			0x000000f800000000ULL,
-    .mmx_565_g =			0x0000000000fc0000ULL,
-    .mmx_565_b =			0x00000000000000f8ULL,
-    .mmx_mask_0 =			0xffffffffffff0000ULL,
-    .mmx_mask_1 =			0xffffffff0000ffffULL,
-    .mmx_mask_2 =			0xffff0000ffffffffULL,
-    .mmx_mask_3 =			0x0000ffffffffffffULL,
-    .mmx_full_alpha =			0x00ff000000000000ULL,
-    .mmx_565_unpack_multiplier =	0x0000008404100840ULL,
-    .mmx_ffff0000ffff0000 =		0xffff0000ffff0000ULL,
-    .mmx_0000ffff00000000 =		0x0000ffff00000000ULL,
-    .mmx_000000000000ffff =		0x000000000000ffffULL,
-};
-
-#define MC(x) ((__m64) c.mmx_##x)
-
-static __inline__ __m64
-shift (__m64 v, int s)
-{
-    if (s > 0)
-	return _mm_slli_si64 (v, s);
-    else if (s < 0)
-	return _mm_srli_si64 (v, -s);
-    else
-	return v;
-}
-
-static __inline__ __m64
-negate (__m64 mask)
-{
-    return _mm_xor_si64 (mask, MC(4x00ff));
-}
-
-static __inline__ __m64
-pix_multiply (__m64 a, __m64 b)
-{
-    __m64 res;
-    
-    res = _mm_mullo_pi16 (a, b);
-    res = _mm_adds_pu16 (res, _mm_srli_pi16 (res, 8));
-    res = _mm_adds_pu16 (res, MC(4x0080));
-    res = _mm_srli_pi16 (res, 8);
-    
-    return res;
-}
-
-static __inline__ __m64
-expand_alpha (__m64 pixel)
-{
-    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(3, 3, 3, 3));
-}
-
-static __inline__ __m64
-expand_alpha_rev (__m64 pixel)
-{
-    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(0, 0, 0, 0));
-}    
-
-static __inline__ __m64
-invert_colors (__m64 pixel)
-{
-    return _mm_shuffle_pi16 (pixel, _MM_SHUFFLE(3, 0, 1, 2));
-}
-
-/* Notes about writing mmx code
- *
- * give memory operands as the second operand. If you give it as the
- * first, gcc will first load it into a register, then use that
- * register
- *
- *   ie. use
- *
- *         _mm_mullo_pi16 (x, mmx_constant);
- *
- *   not
- *
- *         _mm_mullo_pi16 (mmx_constant, x);
- *
- * Also try to minimize dependencies. i.e. when you need a value, try
- * to calculate it from a value that was calculated as early as
- * possible.
- */
-
-static __inline__ __m64
-over (__m64 src, __m64 srca, __m64 dest)
-{
-    return  _mm_adds_pu8 (src, pix_multiply(dest, negate(srca)));
-}
-
-static __inline__ __m64
-over_rev_non_pre (__m64 src, __m64 dest)
-{
-    __m64 srca = expand_alpha (src);
-    __m64 srcfaaa = _mm_or_si64 (srca, MC(full_alpha));
-    
-    return over(pix_multiply(invert_colors(src), srcfaaa), srca, dest);
-}
-
-static __inline__ __m64
-in (__m64 src,
-    __m64 mask)
-{
-    return pix_multiply (src, mask);
-}
-
-static __inline__ __m64
-in_over (__m64 src,
-	 __m64 srca,
-	 __m64 mask,
-	 __m64 dest)
-{
-    return over(in(src, mask), pix_multiply(srca, mask), dest);
-}
-
-static __inline__ __m64
-load8888 (CARD32 v)
-{
-    return _mm_unpacklo_pi8 (_mm_cvtsi32_si64 (v), _mm_setzero_si64());
-}
-
-static __inline__ __m64
-pack8888 (__m64 lo, __m64 hi)
-{
-    __m64 r;
-    r = _mm_packs_pu16 (lo, hi);
-    return r;
-}
-
-/* Expand 16 bits positioned at @pos (0-3) of a mmx register into
- *
- *    00RR00GG00BB
- * 
- * --- Expanding 565 in the low word ---
- * 
- * m = (m << (32 - 3)) | (m << (16 - 5)) | m;
- * m = m & (01f0003f001f);
- * m = m * (008404100840);
- * m = m >> 8;
- * 
- * Note the trick here - the top word is shifted by another nibble to
- * avoid it bumping into the middle word
- */
-static __inline__ __m64
-expand565 (__m64 pixel, int pos)
-{
-    __m64 p = pixel;
-    __m64 t1, t2;
-    
-    /* move pixel to low 16 bit and zero the rest */
-    p = shift (shift (p, (3 - pos) * 16), -48); 
-    
-    t1 = shift (p, 36 - 11);
-    t2 = shift (p, 16 - 5);
-    
-    p = _mm_or_si64 (t1, p);
-    p = _mm_or_si64 (t2, p);
-    p = _mm_and_si64 (p, MC(565_rgb));
-    
-    pixel = _mm_mullo_pi16 (p, MC(565_unpack_multiplier));
-    return _mm_srli_pi16 (pixel, 8);
-}
-
-static __inline__ __m64
-expand8888 (__m64 in, int pos)
-{
-    if (pos == 0)
-	return _mm_unpacklo_pi8 (in, _mm_setzero_si64());
-    else
-	return _mm_unpackhi_pi8 (in, _mm_setzero_si64());
-}
-
-static __inline__ __m64
-pack565 (__m64 pixel, __m64 target, int pos)
-{
-    __m64 p = pixel;
-    __m64 t = target;
-    __m64 r, g, b;
-    
-    r = _mm_and_si64 (p, MC(565_r));
-    g = _mm_and_si64 (p, MC(565_g));
-    b = _mm_and_si64 (p, MC(565_b));
-    
-    r = shift (r, - (32 - 8) + pos * 16);
-    g = shift (g, - (16 - 3) + pos * 16);
-    b = shift (b, - (0  + 3) + pos * 16);
-    
-    if (pos == 0)
-	t = _mm_and_si64 (t, MC(mask_0));
-    else if (pos == 1)
-	t = _mm_and_si64 (t, MC(mask_1));
-    else if (pos == 2)
-	t = _mm_and_si64 (t, MC(mask_2));
-    else if (pos == 3)
-	t = _mm_and_si64 (t, MC(mask_3));
-    
-    p = _mm_or_si64 (r, t);
-    p = _mm_or_si64 (g, p);
-    
-    return _mm_or_si64 (b, p);
-}
-
 void
 fbCompositeSolid_nx8888mmx (CARD8	op,
 			    PicturePtr pSrc,
@@ -899,8 +837,7 @@ fbCompositeSolid_nx8888mmx (CARD8	op,
 	
 	while (w && (unsigned long)dst & 7)
 	{
-	    *dst = (ullong) pack8888(over(vsrc, vsrca, load8888(*dst)),
-				     _mm_setzero_si64());
+	    *dst = store8888(over(vsrc, vsrca, load8888(*dst)));
 	    
 	    w--;
 	    dst++;
@@ -926,7 +863,7 @@ fbCompositeSolid_nx8888mmx (CARD8	op,
 	
 	while (w)
 	{
-	    *dst = (ullong) pack8888(over(vsrc, vsrca, load8888(*dst)), _mm_setzero_si64());
+	    *dst = store8888(over(vsrc, vsrca, load8888(*dst)));
 	    
 	    w--;
 	    dst++;
@@ -1069,7 +1006,7 @@ fbCompositeSolidMask_nx8888x8888Cmmx (CARD8	op,
 	    {
 		__m64 vdest = load8888(*q);
 		vdest = in_over(vsrc, vsrca, load8888(m), vdest);
-		*q = (ullong)pack8888(vdest, _mm_setzero_si64());
+		*q = store8888(vdest);
 	    }
 	    
 	    twidth--;
@@ -1109,7 +1046,7 @@ fbCompositeSolidMask_nx8888x8888Cmmx (CARD8	op,
 	    {
 		__m64 vdest = load8888(*q);
 		vdest = in_over(vsrc, vsrca, load8888(m), vdest);
-		*q = (ullong)pack8888(vdest, _mm_setzero_si64());
+		*q = store8888(vdest);
 	    }
 	    
 	    twidth--;
@@ -1170,7 +1107,7 @@ fbCompositeSrc_8888x8x8888mmx (CARD8	op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (in_over (s, srca, vmask, d), (__m64)_mm_setzero_si64());
+	    *dst = store8888 (in_over (s, srca, vmask, d));
 	    
 	    w--;
 	    dst++;
@@ -1248,7 +1185,7 @@ fbCompositeSrc_8888x8x8888mmx (CARD8	op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (in_over (s, srca, vmask, d), (__m64)_mm_setzero_si64());
+	    *dst = store8888 (in_over (s, srca, vmask, d));
 	    
 	    w--;
 	    dst++;
@@ -1299,7 +1236,7 @@ fbCompositeSrc_8888x8888mmx (CARD8	op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (over (s, expand_alpha (s), d), (__m64)_mm_setzero_si64());
+	    *dst = store8888 (over (s, expand_alpha (s), d));
 	    
 	    w--;
 	    dst++;
@@ -1327,8 +1264,7 @@ fbCompositeSrc_8888x8888mmx (CARD8	op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (over (s, expand_alpha (s), d),
-				     (__m64)_mm_setzero_si64());
+	    *dst = store8888 (over (s, expand_alpha (s), d));
 	    
 	    w--;
 	    dst++;
@@ -1394,7 +1330,7 @@ fbCompositeSolidMask_nx8x8888mmx (CARD8      op,
 	    if (m)
 	    {
 		__m64 vdest = in_over(vsrc, vsrca, expand_alpha_rev ((__m64)m), load8888(*dst));
-		*dst = (ullong)pack8888(vdest, _mm_setzero_si64());
+		*dst = store8888(vdest);
 	    }
 	    
 	    w--;
@@ -1442,7 +1378,7 @@ fbCompositeSolidMask_nx8x8888mmx (CARD8      op,
 	    {
 		__m64 vdest = load8888(*dst);
 		vdest = in_over(vsrc, vsrca, expand_alpha_rev ((__m64)m), vdest);
-		*dst = (ullong)pack8888(vdest, _mm_setzero_si64());
+		*dst = store8888(vdest);
 	    }
 	    
 	    w--;
@@ -1741,7 +1677,7 @@ fbCompositeSrc_8888RevNPx8888mmx (CARD8      op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (over_rev_non_pre (s, d), _mm_setzero_si64());
+	    *dst = store8888 (over_rev_non_pre (s, d));
 	    
 	    w--;
 	    dst++;
@@ -1787,7 +1723,7 @@ fbCompositeSrc_8888RevNPx8888mmx (CARD8      op,
 	    __m64 s = load8888 (*src);
 	    __m64 d = load8888 (*dst);
 	    
-	    *dst = (ullong)pack8888 (over_rev_non_pre (s, d), _mm_setzero_si64());
+	    *dst = store8888 (over_rev_non_pre (s, d));
 	    
 	    w--;
 	    dst++;
