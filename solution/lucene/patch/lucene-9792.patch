diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index e790171..baf4a1e 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -17,39 +17,42 @@
 
 package org.apache.lucene.analysis.standard;
 
-import java.io.IOException;
-import java.io.Reader;
-
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.Version;
 
-/** A grammar-based tokenizer constructed with JFlex
- *
- * <p> This should be a good tokenizer for most European-language documents:
- *
- * <ul>
- *   <li>Splits words at punctuation characters, removing punctuation. However, a 
- *     dot that's not followed by whitespace is considered part of a token.
- *   <li>Splits words at hyphens, unless there's a number in the token, in which case
- *     the whole token is interpreted as a product number and is not split.
- *   <li>Recognizes email addresses and internet hostnames as one token.
- * </ul>
- *
+import java.io.IOException;
+import java.io.Reader;
+
+/** A grammar-based tokenizer constructed with JFlex.
+ * <p>
+ * As of Lucene version 3.1, this class implements the Word Break rules from the
+ * Unicode Text Segmentation algorithm, as specified in 
+ * <a href="http://unicode.org/reports/tr29/">Unicode Standard Annex #29</a>.
+ * <p/>
+ * <b>WARNING</b>: Because JFlex does not support Unicode supplementary 
+ * characters (characters above the Basic Multilingual Plane, which contains
+ * those up to and including U+FFFF), this scanner will not recognize them
+ * properly.  If you need to be able to process text containing supplementary 
+ * characters, consider using the ICU4J-backed implementation in contrib/icu  
+ * ({@link org.apache.lucene.analysis.icu.segmentation.ICUTokenizer})
+ * instead of this class, since the ICU4J-backed implementation does not have
+ * this limitation.
  * <p>Many applications have specific tokenizer needs.  If this tokenizer does
  * not suit your application, please consider copying this source code
  * directory to your project and maintaining your own grammar-based tokenizer.
  *
  * <a name="version"/>
  * <p>You must specify the required {@link Version}
- * compatibility when creating StandardAnalyzer:
+ * compatibility when creating StandardTokenizer:
  * <ul>
- *   <li> As of 2.4, Tokens incorrectly identified as acronyms
- *        are corrected (see <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a>
+ *   <li> As of 3.1, StandardTokenizer implements Unicode text segmentation.
+ *   If you use a previous version number, you get the exact behavior of
+ *   {@link ClassicTokenizer} for backwards compatibility.
  * </ul>
  */
 
@@ -58,12 +61,22 @@ public final class StandardTokenizer extends Tokenizer {
   private StandardTokenizerInterface scanner;
 
   public static final int ALPHANUM          = 0;
+  /** @deprecated */
+  @Deprecated
   public static final int APOSTROPHE        = 1;
+  /** @deprecated */
+  @Deprecated
   public static final int ACRONYM           = 2;
+  /** @deprecated */
+  @Deprecated
   public static final int COMPANY           = 3;
   public static final int EMAIL             = 4;
+  /** @deprecated */
+  @Deprecated
   public static final int HOST              = 5;
   public static final int NUM               = 6;
+  /** @deprecated */
+  @Deprecated
   public static final int CJ                = 7;
 
   /**
@@ -73,6 +86,11 @@ public final class StandardTokenizer extends Tokenizer {
   @Deprecated
   public static final int ACRONYM_DEP       = 8;
 
+  public static final int URL = 9;
+  public static final int SOUTHEAST_ASIAN = 10;
+  public static final int IDEOGRAPHIC = 11;
+  public static final int HIRAGANA = 12;
+  
   /** String token types that correspond to token type int constants */
   public static final String [] TOKEN_TYPES = new String [] {
     "<ALPHANUM>",
@@ -83,7 +101,11 @@ public final class StandardTokenizer extends Tokenizer {
     "<HOST>",
     "<NUM>",
     "<CJ>",
-    "<ACRONYM_DEP>"
+    "<ACRONYM_DEP>",
+    "<URL>",
+    "<SOUTHEAST_ASIAN>",
+    "<IDEOGRAPHIC>",
+    "<HIRAGANA>"
   };
 
   private boolean replaceInvalidAcronym;
@@ -132,7 +154,7 @@ public final class StandardTokenizer extends Tokenizer {
 
   private final void init(Reader input, Version matchVersion) {
     this.scanner = matchVersion.onOrAfter(Version.LUCENE_31) ?
-      new StandardTokenizerImpl31(input) : new StandardTokenizerImplOrig(input);
+      new StandardTokenizerImpl(input) : new ClassicTokenizerImpl(input);
     if (matchVersion.onOrAfter(Version.LUCENE_24)) {
       replaceInvalidAcronym = true;
     } else {
