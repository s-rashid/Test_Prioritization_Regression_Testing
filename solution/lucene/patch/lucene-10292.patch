diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer.java
index b5a8575..18d047f 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer.java
@@ -1,4 +1,4 @@
-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 10/2/10 6:07 PM */
+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 10/3/10 9:07 AM */
 
 package org.apache.lucene.analysis.standard;
 
@@ -48,8 +48,8 @@ import org.apache.lucene.util.AttributeSource;
  * characters (characters above the Basic Multilingual Plane, which contains
  * those up to and including U+FFFF), this scanner will not recognize them
  * properly.  If you need to be able to process text containing supplementary 
- * characters, consider using the ICU4J-backed implementation in contrib/icu  
- * ({@link org.apache.lucene.analysis.icu.segmentation.ICUTokenizer})
+ * characters, consider using the ICU4J-backed implementation in modules/analysis/icu  
+ * (org.apache.lucene.analysis.icu.segmentation.ICUTokenizer)
  * instead of this class, since the ICU4J-backed implementation does not have
  * this limitation.
  */
@@ -389,7 +389,8 @@ public final class UAX29Tokenizer extends Tokenizer {
    * scripts (Thai, Lao, Myanmar, Khmer, etc.).  Sequences of these are kept 
    * together as as a single token rather than broken up, because the logic
    * required to break them at word boundaries is too complex for UAX#29.
-   * {@see Unicode Line Breaking Algorithm http://www.unicode.org/reports/tr14/#SA}
+   * <p>
+   * See Unicode Line Breaking Algorithm: http://www.unicode.org/reports/tr14/#SA
    */
   public static final String SOUTH_EAST_ASIAN_TYPE = "<SOUTHEAST_ASIAN>";
