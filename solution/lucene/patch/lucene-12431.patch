diff --git a/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java b/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
index a12bbd3..5eaddfc 100644
--- a/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
+++ b/lucene/src/java/org/apache/lucene/index/DocFieldProcessorPerThread.java
@@ -23,12 +23,12 @@ import java.util.HashSet;
 import java.util.List;
 import java.io.IOException;
 
+import org.apache.lucene.document.AbstractField;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Fieldable;
 import org.apache.lucene.index.codecs.docvalues.DocValuesConsumer;
-import org.apache.lucene.index.values.ValuesAttribute;
+import org.apache.lucene.index.values.PerDocFieldValues;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.RamUsageEstimator;
 
 /**
@@ -254,15 +254,16 @@ final class DocFieldProcessorPerThread extends DocConsumerPerThread {
       final Fieldable fieldable = perField.fields[0];
       perField.consumer.processFields(perField.fields, perField.fieldCount);
      
-      if(!fieldable.hasFieldAttribute())
+      if (!(fieldable instanceof AbstractField)) {
         continue;
-      final AttributeSource attrSource = fieldable.getFieldAttributes();
-      if(!attrSource.hasAttribute(ValuesAttribute.class))
+      }
+      final PerDocFieldValues docValues = ((AbstractField)fieldable).getDocValues();
+      if (docValues == null) {
         continue;
-      final ValuesAttribute attribute = attrSource.getAttribute(ValuesAttribute.class);
+      }
       final DocValuesConsumer consumer = docFieldProcessor.docValuesConsumer(docState.docWriter.directory,
-              docState.docWriter.segment, fieldable.name(), attribute, perField.fieldInfo);
-      consumer.add(docState.docID, attribute);
+              docState.docWriter.segment, fieldable.name(), docValues, perField.fieldInfo);
+      consumer.add(docState.docID, docValues);
     }
     if (docState.maxTermPrefix != null && docState.infoStream != null) {
       docState.infoStream.println("WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length " + DocumentsWriter.MAX_TERM_LENGTH_UTF8 + "), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '" + docState.maxTermPrefix + "...'");
