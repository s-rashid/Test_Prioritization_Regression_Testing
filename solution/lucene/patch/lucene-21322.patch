diff --git a/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java b/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
index 36abeee..0105571 100644
--- a/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
+++ b/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
@@ -20,7 +20,6 @@ package org.apache.lucene.index;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.store.BufferedIndexInput;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.codecs.CodecProvider;
 import org.apache.lucene.util.BytesRef;
@@ -30,25 +29,23 @@ import java.util.Collection;
 
 public class TestSegmentMerger extends LuceneTestCase {
   //The variables for the new merged segment
-  private Directory mergedDir = new RAMDirectory();
+  private Directory mergedDir;
   private String mergedSegment = "test";
   //First segment to be merged
-  private Directory merge1Dir = new RAMDirectory();
+  private Directory merge1Dir;
   private Document doc1 = new Document();
   private SegmentReader reader1 = null;
   //Second Segment to be merged
-  private Directory merge2Dir = new RAMDirectory();
+  private Directory merge2Dir;
   private Document doc2 = new Document();
   private SegmentReader reader2 = null;
-  
-
-  public TestSegmentMerger(String s) {
-    super(s);
-  }
 
   @Override
-  protected void setUp() throws Exception {
+  public void setUp() throws Exception {
     super.setUp();
+    mergedDir = newDirectory();
+    merge1Dir = newDirectory();
+    merge2Dir = newDirectory();
     DocHelper.setupDoc(doc1);
     SegmentInfo info1 = DocHelper.writeDoc(merge1Dir, doc1);
     DocHelper.setupDoc(doc2);
@@ -57,6 +54,16 @@ public class TestSegmentMerger extends LuceneTestCase {
     reader2 = SegmentReader.get(true, info2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
   }
 
+  @Override
+  public void tearDown() throws Exception {
+    reader1.close();
+    reader2.close();
+    mergedDir.close();
+    merge1Dir.close();
+    merge2Dir.close();
+    super.tearDown();
+  }
+
   public void test() {
     assertTrue(mergedDir != null);
     assertTrue(merge1Dir != null);
@@ -64,18 +71,17 @@ public class TestSegmentMerger extends LuceneTestCase {
     assertTrue(reader1 != null);
     assertTrue(reader2 != null);
   }
-  
-  public void testMerge() throws IOException {                             
-    SegmentMerger merger = new SegmentMerger(mergedDir, IndexWriter.DEFAULT_TERM_INDEX_INTERVAL, mergedSegment, null, CodecProvider.getDefault(), null);
+
+  public void testMerge() throws IOException {
+    SegmentMerger merger = new SegmentMerger(mergedDir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, mergedSegment, null, CodecProvider.getDefault(), null, new FieldInfos());
     merger.add(reader1);
     merger.add(reader2);
     int docsMerged = merger.merge();
-    merger.closeReaders();
     assertTrue(docsMerged == 2);
     //Should be able to open a new SegmentReader against the new directory
-    SegmentReader mergedReader = SegmentReader.get(false, mergedDir, new SegmentInfo(mergedSegment, docsMerged, mergedDir, false, 
-        merger.hasProx(), merger.getCodec()), BufferedIndexInput.BUFFER_SIZE, true, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR, null);
-
+    SegmentReader mergedReader = SegmentReader.get(false, mergedDir, new SegmentInfo(mergedSegment, docsMerged, mergedDir, false, merger.fieldInfos().hasProx(),
+                                                                                     merger.getSegmentCodecs(), merger.fieldInfos().hasVectors()),
+                                                   BufferedIndexInput.BUFFER_SIZE, true, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
     assertTrue(mergedReader != null);
     assertTrue(mergedReader.numDocs() == 2);
     Document newDoc1 = mergedReader.document(0);
@@ -85,19 +91,19 @@ public class TestSegmentMerger extends LuceneTestCase {
     Document newDoc2 = mergedReader.document(1);
     assertTrue(newDoc2 != null);
     assertTrue(DocHelper.numFields(newDoc2) == DocHelper.numFields(doc2) - DocHelper.unstored.size());
-    
+
     DocsEnum termDocs = MultiFields.getTermDocsEnum(mergedReader,
                                                     MultiFields.getDeletedDocs(mergedReader),
                                                     DocHelper.TEXT_FIELD_2_KEY,
                                                     new BytesRef("field"));
     assertTrue(termDocs != null);
     assertTrue(termDocs.nextDoc() != DocsEnum.NO_MORE_DOCS);
-    
+
     Collection<String> stored = mergedReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);
     assertTrue(stored != null);
     //System.out.println("stored size: " + stored.size());
     assertTrue("We do not have 3 fields that were indexed with term vector",stored.size() == 3);
-    
+
     TermFreqVector vector = mergedReader.getTermFreqVector(0, DocHelper.TEXT_FIELD_2_KEY);
     assertTrue(vector != null);
     BytesRef [] terms = vector.getTerms();
@@ -108,7 +114,7 @@ public class TestSegmentMerger extends LuceneTestCase {
     assertTrue(freqs != null);
     //System.out.println("Freqs size: " + freqs.length);
     assertTrue(vector instanceof TermPositionVector == true);
-    
+
     for (int i = 0; i < terms.length; i++) {
       String term = terms[i].utf8ToString();
       int freq = freqs[i];
@@ -118,5 +124,6 @@ public class TestSegmentMerger extends LuceneTestCase {
     }
 
     TestSegmentReader.checkNorms(mergedReader);
-  }    
+    mergedReader.close();
+  }
 }
