diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java
index f974436..8449e12 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java
@@ -1,4 +1,4 @@
-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 10/2/10 6:07 PM */
+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 10/3/10 9:07 AM */
 
 package org.apache.lucene.analysis.standard;
 
@@ -42,8 +42,8 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
  * characters (characters above the Basic Multilingual Plane, which contains
  * those up to and including U+FFFF), this scanner will not recognize them
  * properly.  If you need to be able to process text containing supplementary 
- * characters, consider using the ICU4J-backed implementation in contrib/icu  
- * ({@link org.apache.lucene.analysis.icu.segmentation.ICUTokenizer})
+ * characters, consider using the ICU4J-backed implementation in modules/analysis/icu  
+ * (org.apache.lucene.analysis.icu.segmentation.ICUTokenizer)
  * instead of this class, since the ICU4J-backed implementation does not have
  * this limitation.
  */
@@ -2388,7 +2388,8 @@ public final class StandardTokenizerImpl implements StandardTokenizerInterface {
    * scripts (Thai, Lao, Myanmar, Khmer, etc.).  Sequences of these are kept 
    * together as as a single token rather than broken up, because the logic
    * required to break them at word boundaries is too complex for UAX#29.
-   * {@see Unicode Line Breaking Algorithm http://www.unicode.org/reports/tr14/#SA}
+   * <p>
+   * See Unicode Line Breaking Algorithm: http://www.unicode.org/reports/tr14/#SA
    */
   public static final int SOUTH_EAST_ASIAN_TYPE = StandardTokenizer.SOUTHEAST_ASIAN;
