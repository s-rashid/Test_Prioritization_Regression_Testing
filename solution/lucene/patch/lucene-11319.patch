diff --git a/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java b/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
index dee8168..4db1363 100644
--- a/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
+++ b/lucene/src/java/org/apache/lucene/index/DocFieldProcessor.java
@@ -18,11 +18,13 @@ package org.apache.lucene.index;
  */
 
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.index.codecs.FieldsConsumer;
 import org.apache.lucene.index.values.Ints;
 import org.apache.lucene.index.values.Floats;
 import org.apache.lucene.index.values.Bytes;
 import org.apache.lucene.index.values.ValuesAttribute;
 import org.apache.lucene.index.values.Writer;
+import org.apache.lucene.index.values.codec.DocValuesConsumer;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FloatsRef;
 import org.apache.lucene.util.LongsRef;
@@ -48,154 +50,33 @@ final class DocFieldProcessor extends DocConsumer {
   final FieldInfos fieldInfos = new FieldInfos();
   final DocFieldConsumer consumer;
   final StoredFieldsWriter fieldsWriter;
-  final private Map<String,IndexValuesProcessor> indexValues = new HashMap<String,IndexValuesProcessor>();
-
-  synchronized IndexValuesProcessor getProcessor(Directory dir, String segment, String name, ValuesAttribute attr, FieldInfo fieldInfo)
-    throws IOException {
-    if(attr == null)
-      return null;
-    IndexValuesProcessor p = indexValues.get(name);
-    if (p == null) {
-        org.apache.lucene.index.values.Values v = attr.type();
-        final String id = segment + "_" + fieldInfo.number;
-        switch(v) {
-        case PACKED_INTS:
-          p = new IntValuesProcessor(dir, id, false);
-          break;
-        case PACKED_INTS_FIXED:
-          p = new IntValuesProcessor(dir, id, true);
-          break;
-        case SIMPLE_FLOAT_4BYTE:
-          p = new FloatValuesProcessor(dir, id, 4);
-          break;
-        case SIMPLE_FLOAT_8BYTE:
-          p = new FloatValuesProcessor(dir, id, 8);
-          break;
-        case BYTES_FIXED_STRAIGHT:
-          p = new BytesValuesProcessor(dir, id, true, null, Bytes.Mode.STRAIGHT);
-          break;
-        case BYTES_FIXED_DEREF:
-          p = new BytesValuesProcessor(dir, id, true, null, Bytes.Mode.DEREF);
-          break;
-        case BYTES_FIXED_SORTED:
-          p = new BytesValuesProcessor(dir, id, true, attr.bytesComparator(), Bytes.Mode.SORTED);
-          break;
-        case BYTES_VAR_STRAIGHT:
-          p = new BytesValuesProcessor(dir, id, false, null, Bytes.Mode.STRAIGHT);
-          break;
-        case BYTES_VAR_DEREF:
-          p = new BytesValuesProcessor(dir, id, false, null, Bytes.Mode.DEREF);
-          break;
-        case BYTES_VAR_SORTED:
-          p = new BytesValuesProcessor(dir, id, false, attr.bytesComparator(), Bytes.Mode.SORTED);
-          break;
-        }
-        fieldInfo.setIndexValues(v);
-        indexValues.put(name, p);
-    }
-
-    return p;
-  }
-
-  static abstract class IndexValuesProcessor {
-    public abstract void add(int docID, String name, ValuesAttribute attr) throws IOException;
-    public abstract void finish(int docCount) throws IOException;
-    public abstract void files(Collection<String> files) throws IOException;
-  }
-
-  static class FloatValuesProcessor extends IndexValuesProcessor {
-    private final Writer writer;
-    private final String id;
-
-    public FloatValuesProcessor(Directory dir, String id, int precision) throws IOException {
-      this.id = id;
-      writer = Floats.getWriter(dir, id, precision);
-    }
-
-    @Override
-    public void add(int docID, String name, ValuesAttribute attr) throws IOException {
-        final FloatsRef floats = attr.floats();
-        if(floats != null) {
-          writer.add(docID, floats.get());
-          return;
-        }
-      throw new IllegalArgumentException("could not extract float/double from field " + name);
-    }
-
-    @Override
-    public void finish(int docCount) throws IOException {
-      writer.finish(docCount);
-    }
-
-    @Override
-    public void files(Collection<String> files) {
-      Floats.files(id, files);
-    }
-  }
-
-  static class IntValuesProcessor extends IndexValuesProcessor {
-    private final Writer writer;
-    private final String id;
-
-    public IntValuesProcessor(Directory dir, String id, boolean fixedArray) throws IOException {
-      this.id = id;
-      writer = Ints.getWriter(dir, id, fixedArray);
-    }
-
-    @Override
-      public void add(int docID, String name, ValuesAttribute attr) throws IOException {
-        final LongsRef ints = attr.ints();
-        if(ints != null) {
-          writer.add(docID, ints.get());
-          return;
-        }
-      throw new IllegalArgumentException("could not extract int/long from field " + name);
-    }
-
-    @Override
-    public void finish(int docCount) throws IOException {
-      writer.finish(docCount);
-    }
-
-    @Override
-    public void files(Collection<String> files) throws IOException {
-      Ints.files(id, files);
-    }
-  }
-
-  static class BytesValuesProcessor extends IndexValuesProcessor {
-    private final Writer writer;
-    private final String id;
-    private final Directory dir;
-
-    public BytesValuesProcessor(Directory dir, String id, boolean fixedSize, Comparator<BytesRef> comp, Bytes.Mode mode) throws IOException {
-      this.id = id;
-      writer = Bytes.getWriter(dir, id, mode,comp, fixedSize);
-      this.dir = dir;
-    }
-
-    // nocommit -- make this thread private and not sync'd
-    @Override
-    public synchronized void add(int docID, String name, ValuesAttribute attr) throws IOException {
-      final BytesRef bytes = attr.bytes();
-      if(bytes != null) {
-        writer.add(docID, bytes);
-        return;
+  final private Map<String,DocValuesConsumer> docValues = new HashMap<String,DocValuesConsumer>();
+  private FieldsConsumer fieldsConsumer; // TODO this should be encapsulated in DocumentsWriter
+
+  synchronized DocValuesConsumer docValuesConsumer(Directory dir,
+      String segment, String name, ValuesAttribute attr, FieldInfo fieldInfo)
+      throws IOException {
+    DocValuesConsumer valuesConsumer;
+    if ((valuesConsumer = docValues.get(name)) == null) {
+      fieldInfo.setIndexValues(attr.type());
+
+      if(fieldsConsumer == null) {
+        /* nocommit -- this is a hack and only works since DocValuesCodec supports initializing the FieldsConsumer twice.
+         * we need to find a way that allows us to obtain a FieldsConsumer per DocumentsWriter. Currently some codecs rely on 
+         * the SegmentsWriteState passed in right at the moment when the segment is flushed (doccount etc) but we need the consumer earlier 
+         * to support docvalues and later on stored fields too.  
+         */
+      SegmentWriteState state = docWriter.segWriteState();
+      fieldsConsumer = state.codec.fieldsConsumer(state);
       }
-      throw new IllegalArgumentException("could not extract byte[] from field " + name);
+      valuesConsumer = fieldsConsumer.addValuesField(fieldInfo);
+      docValues.put(name, valuesConsumer);
     }
+    return valuesConsumer;
 
-    @Override
-    public void finish(int docCount) throws IOException {
-      writer.finish(docCount);
-    }
-
-    @Override
-    public void files(Collection<String> files) throws IOException {
-      Bytes.files(dir, id, files);
-    }
   }
 
+ 
   public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer) {
     this.docWriter = docWriter;
     this.consumer = consumer;
@@ -221,13 +102,17 @@ final class DocFieldProcessor extends DocConsumer {
     fieldsWriter.flush(state);
     consumer.flush(childThreadsAndFields, state);
 
-    for(IndexValuesProcessor p : indexValues.values()) {
+    for(DocValuesConsumer p : docValues.values()) {
       if (p != null) {
         p.finish(state.numDocs);
         p.files(state.flushedFiles);
       }
     }
-    indexValues.clear();
+    docValues.clear();
+    if(fieldsConsumer != null) {
+      fieldsConsumer.close(); // nocommit this should go away
+      fieldsConsumer = null;
+    }
 
     // Important to save after asking consumer to flush so
     // consumer can alter the FieldInfo* if necessary.  EG,
