diff --git a/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java b/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
index 810c6a0..e445cfb 100644
--- a/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
+++ b/lucene/src/java/org/apache/lucene/index/values/FixedSortedBytesImpl.java
@@ -33,6 +33,7 @@ import org.apache.lucene.util.ByteBlockPool;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefHash;
 import org.apache.lucene.util.CodecUtil;
+import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.ByteBlockPool.Allocator;
 import org.apache.lucene.util.ByteBlockPool.DirectAllocator;
@@ -52,88 +53,93 @@ class FixedSortedBytesImpl {
     private int[] docToEntry;
     private final Comparator<BytesRef> comp;
 
-   
     private final BytesRefHash hash = new BytesRefHash(pool);
-    
-    public Writer(Directory dir, String id,  Comparator<BytesRef> comp) throws IOException {
+
+    public Writer(Directory dir, String id, Comparator<BytesRef> comp)
+        throws IOException {
       this(dir, id, comp, new DirectAllocator(ByteBlockPool.BYTE_BLOCK_SIZE),
           new AtomicLong());
     }
 
-    public Writer(Directory dir, String id,  Comparator<BytesRef> comp, Allocator allocator, AtomicLong bytesUsed) throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, false, false, new ByteBlockPool(allocator), bytesUsed);
+    public Writer(Directory dir, String id, Comparator<BytesRef> comp,
+        Allocator allocator, AtomicLong bytesUsed) throws IOException {
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, false, false,
+          new ByteBlockPool(allocator), bytesUsed);
       docToEntry = new int[1];
-//      docToEntry[0] = -1;
+      // docToEntry[0] = -1;
       bytesUsed.addAndGet(RamUsageEstimator.NUM_BYTES_INT);
       this.comp = comp;
     }
 
     @Override
     synchronized public void add(int docID, BytesRef bytes) throws IOException {
-      if(bytes.length == 0)
+      if (bytes.length == 0)
         return; // default - skip it
       if (size == -1) {
         size = bytes.length;
         initDataOut();
         datOut.writeInt(size);
       } else if (bytes.length != size) {
-        throw new IllegalArgumentException("expected bytes size=" + size + " but got " + bytes.length);
+        throw new IllegalArgumentException("expected bytes size=" + size
+            + " but got " + bytes.length);
       }
       if (docID >= docToEntry.length) {
         int[] newArray = new int[ArrayUtil.oversize(1 + docID,
             RamUsageEstimator.NUM_BYTES_INT)];
         System.arraycopy(docToEntry, 0, newArray, 0, docToEntry.length);
-//        Arrays.fill(newArray, docToEntry.length, newArray.length, -1);
+        // Arrays.fill(newArray, docToEntry.length, newArray.length, -1);
 
-        bytesUsed.addAndGet((newArray.length - docToEntry.length) * RamUsageEstimator.NUM_BYTES_INT);
+        bytesUsed.addAndGet((newArray.length - docToEntry.length)
+            * RamUsageEstimator.NUM_BYTES_INT);
         docToEntry = newArray;
       }
       int e = hash.add(bytes);
-      docToEntry[docID] = 1+(e < 0? (-e)-1: e);
+      docToEntry[docID] = 1 + (e < 0 ? (-e) - 1 : e);
     }
 
-
     // Important that we get docCount, in case there were
     // some last docs that we didn't see
     @Override
     synchronized public void finish(int docCount) throws IOException {
-      if(datOut == null)// no data added
+      if (datOut == null)// no data added
         return;
       initIndexOut();
       final int[] sortedEntries = hash.sort(comp);
       final int count = hash.size();
-      int[] address= new int[count];
+      int[] address = new int[count];
       // first dump bytes data, recording address as we go
-      for(int i=0;i<count;i++) {
+      for (int i = 0; i < count; i++) {
         final int e = sortedEntries[i];
         final BytesRef bytes = hash.get(e, new BytesRef());
         assert bytes.length == size;
         datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);
-        address[e] = 1+i;
+        address[e] = 1 + i;
       }
 
       idxOut.writeInt(count);
 
       // next write index
-      PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount, PackedInts.bitsRequired(count));
+      PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount, PackedInts
+          .bitsRequired(count));
       final int limit;
       if (docCount > docToEntry.length) {
         limit = docToEntry.length;
       } else {
         limit = docCount;
       }
-      for(int i=0;i<limit;i++) {
+      for (int i = 0; i < limit; i++) {
         final int e = docToEntry[i];
         if (e == 0) {
           // null is encoded as zero
           w.add(0);
         } else {
-          assert e > 0 && e <= count: "index must  0 > && <= " + count + " was: " + e;
-          w.add(address[e-1]);
+          assert e > 0 && e <= count : "index must  0 > && <= " + count
+              + " was: " + e;
+          w.add(address[e - 1]);
         }
       }
 
-      for(int i=limit;i<docCount;i++) {
+      for (int i = limit; i < docCount; i++) {
         w.add(0);
       }
       w.finish();
@@ -144,56 +150,45 @@ class FixedSortedBytesImpl {
       docToEntry = null;
     }
   }
-  
+
   public static class Reader extends BytesReaderBase {
-    // nocommit -- allow/require byte[] paging here?
     private final int size;
 
-    public Reader(Directory dir, String id, int maxDoc)
-      throws IOException {
+    public Reader(Directory dir, String id, int maxDoc) throws IOException {
       super(dir, id, CODEC_NAME, VERSION_START, true);
       size = datIn.readInt();
     }
 
     @Override
-    public org.apache.lucene.index.values.DocValues.Source load() throws IOException {
+    public org.apache.lucene.index.values.DocValues.Source load()
+        throws IOException {
       return loadSorted(null);
     }
 
     @Override
-    public SortedSource loadSorted(Comparator<BytesRef> comp) throws IOException {
-      return new Source(cloneData(), cloneIndex(), size, comp);
+    public SortedSource loadSorted(Comparator<BytesRef> comp)
+        throws IOException {
+      final IndexInput idxInput = cloneIndex();
+      final IndexInput datInput = cloneData();
+      datInput.seek(CodecUtil.headerLength(CODEC_NAME) + 4);
+      idxInput.seek(CodecUtil.headerLength(CODEC_NAME));
+      return new Source(datInput, idxInput, size, idxInput.readInt(), comp);
     }
 
     private static class Source extends BytesBaseSortedSource {
 
-      // TODO: paged data
-      private final byte[] data;
-      private final BytesRef bytesRef = new BytesRef();
       private final PackedInts.Reader index;
-      private final LookupResult lookupResult = new LookupResult();
       private final int numValue;
-      private final Comparator<BytesRef> comp;
       private final int size;
 
-      public Source(IndexInput datIn, IndexInput idxIn, int size, Comparator<BytesRef> comp) throws IOException {
-        super(datIn, idxIn);
+      public Source(IndexInput datIn, IndexInput idxIn, int size, int numValues,
+          Comparator<BytesRef> comp) throws IOException {
+        super(datIn, idxIn, comp, new PagedBytes(PAGED_BYTES_BITS), size*numValues );
         this.size = size;
-        datIn.seek(CodecUtil.headerLength(CODEC_NAME) + 4);
-        idxIn.seek(CodecUtil.headerLength(CODEC_NAME));
-
-        numValue = idxIn.readInt();
-        data = new byte[size*numValue];
-        datIn.readBytes(data, 0, size*numValue);
-        datIn.close();
-
+        this.numValue = numValues;
         index = PackedInts.getReader(idxIn);
-        idxIn.close(); // do we need to close that here?
 
-        bytesRef.bytes = data;
         bytesRef.length = size;
-        // default byte sort order 
-        this.comp = comp==null?BytesRef.getUTF8SortedAsUnicodeComparator():comp;
       }
 
       @Override
@@ -202,59 +197,37 @@ class FixedSortedBytesImpl {
       }
 
       @Override
-      public BytesRef getByOrd(int ord) {
-        if (ord == 0) {
-          return defaultValue;
-        } else {
-          bytesRef.offset = ((ord-1) * size);
-          return bytesRef;
-        }
-      }
-
-      @Override
       public LookupResult getByValue(BytesRef bytes) {
-        return binarySearch(bytes, 0, numValue-1);
+        return binarySearch(bytes, 0, numValue - 1);
       }
 
       public long ramBytesUsed() {
         // TODO(simonw): move ram calcultation to PackedInts?
-        return RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + data.length +
-            (RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + index.getBitsPerValue() * index.size());
+        return RamUsageEstimator.NUM_BYTES_ARRAY_HEADER
+            + size
+            * numValue
+            + (RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + index
+                .getBitsPerValue()
+                * index.size());
       }
 
       @Override
       public int getValueCount() {
         return numValue;
       }
-
-      private LookupResult binarySearch(BytesRef b, int low, int high) {
-        
-        while (low <= high) {
-          int mid = (low + high) >>> 1;
-          bytesRef.offset = mid * size;
-          int cmp = comp.compare(bytesRef, b);
-          if (cmp < 0) {
-            low = mid + 1;
-          } else if (cmp > 0) {
-            high = mid - 1;
-          } else {
-            lookupResult.ord = mid+1;
-            lookupResult.found = true;
-            return lookupResult;
-          }
-        }
-        lookupResult.ord = low;
-        lookupResult.found = false;
-        return lookupResult;
+      @Override
+      protected BytesRef deref(int ord) {
+        return data.fill(bytesRef, (ord* size), size);
       }
     }
 
     @Override
     public ValuesEnum getEnum(AttributeSource source) throws IOException {
-        // do unsorted
-        return new DerefBytesEnum(source, cloneData(), cloneIndex(), CODEC_NAME, size);
+      // do unsorted
+      return new DerefBytesEnum(source, cloneData(), cloneIndex(), CODEC_NAME,
+          size);
     }
-    
+
     @Override
     public Values type() {
       return Values.BYTES_FIXED_SORTED;
