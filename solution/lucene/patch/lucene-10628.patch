diff --git a/lucene/src/java/org/apache/lucene/index/SegmentMerger.java b/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
index 70ed9f0..4546b3d 100644
--- a/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
+++ b/lucene/src/java/org/apache/lucene/index/SegmentMerger.java
@@ -31,6 +31,12 @@ import org.apache.lucene.index.codecs.CodecProvider;
 import org.apache.lucene.index.codecs.Codec;
 import org.apache.lucene.index.codecs.MergeState;
 import org.apache.lucene.index.codecs.FieldsConsumer;
+import org.apache.lucene.index.values.Bytes;
+import org.apache.lucene.index.values.Ints;
+import org.apache.lucene.index.values.Reader;
+import org.apache.lucene.index.values.Floats;
+import org.apache.lucene.index.values.Values;
+import org.apache.lucene.index.values.Writer;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
@@ -157,6 +163,8 @@ final class SegmentMerger {
     if (mergeDocStores && fieldInfos.hasVectors())
       mergeVectors();
 
+    mergeIndexValues();
+
     return mergedDocs;
   }
 
@@ -170,6 +178,12 @@ final class SegmentMerger {
       reader.close();
     }
   }
+  
+  private void addIfExists(Set<String> files, String file, Directory dir) throws IOException{
+    if(dir.fileExists(file)){
+      files.add(file);
+    }
+  }
 
   final List<String> createCompoundFile(String fileName, final SegmentInfo info)
           throws IOException {
@@ -183,13 +197,20 @@ final class SegmentMerger {
                              !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
         fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
     }
-
     codec.files(directory, info, fileSet);
     
     // Fieldable norm files
-    int numFIs = fieldInfos.size();
+    final int numFIs = fieldInfos.size();
     for (int i = 0; i < numFIs; i++) {
-      FieldInfo fi = fieldInfos.fieldInfo(i);
+      final FieldInfo fi = fieldInfos.fieldInfo(i);
+      // Index Values aka. CSF
+      if (fi.indexValues != null) {
+        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer
+            .toString(fi.number), IndexFileNames.CSF_DATA_EXTENSION), directory);
+        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer
+            .toString(fi.number), IndexFileNames.CSF_INDEX_EXTENSION),
+            directory);
+      }
       if (fi.isIndexed && !fi.omitNorms) {
         fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
         break;
@@ -288,10 +309,18 @@ final class SegmentMerger {
         int numReaderFieldInfos = readerFieldInfos.size();
         for (int j = 0; j < numReaderFieldInfos; j++) {
           FieldInfo fi = readerFieldInfos.fieldInfo(j);
-          fieldInfos.add(fi.name, fi.isIndexed, fi.storeTermVector,
-              fi.storePositionWithTermVector, fi.storeOffsetWithTermVector,
-              !reader.hasNorms(fi.name), fi.storePayloads,
-              fi.omitTermFreqAndPositions);
+          FieldInfo merged = fieldInfos.add(fi.name, fi.isIndexed, fi.storeTermVector,
+                                            fi.storePositionWithTermVector, fi.storeOffsetWithTermVector,
+                                            !reader.hasNorms(fi.name), fi.storePayloads,
+                                            fi.omitTermFreqAndPositions);
+          final Values fiIndexValues = fi.indexValues;
+          final Values mergedIndexValues = merged.indexValues;
+          if (mergedIndexValues == null) {
+            merged.setIndexValues(fiIndexValues);
+          } else if (mergedIndexValues != fiIndexValues) {
+            // nocommit -- what to do?
+            throw new IllegalStateException("cannot merge field " + fi.name + " indexValues changed from " + mergedIndexValues + " to " + fiIndexValues);
+          }
         }
       } else {
         addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false, false);
@@ -302,6 +331,8 @@ final class SegmentMerger {
         addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.STORES_PAYLOADS), false, false, false, true, false);
         addIndexed(reader, fieldInfos, reader.getFieldNames(FieldOption.INDEXED), false, false, false, false, false);
         fieldInfos.add(reader.getFieldNames(FieldOption.UNINDEXED), false);
+
+        // nocommit -- how should we handle index values here?
       }
     }
     fieldInfos.write(directory, segment + ".fnm");
@@ -362,6 +393,77 @@ final class SegmentMerger {
     return docCount;
   }
 
+  private void mergeIndexValues() throws IOException {
+    final int numFields = fieldInfos.size();
+    for (int i = 0; i < numFields; i++) {
+      final FieldInfo fieldInfo = fieldInfos.fieldInfo(i);
+      final Values v = fieldInfo.indexValues;
+      // nocommit we need some kind of compatibility notation for values such
+      // that two slighly different segments can be merged eg. fixed vs.
+      // variable byte len or float32 vs. float64
+
+      if (v != null) {
+        int docBase = 0;
+        final List<Writer.MergeState> mergeStates = new ArrayList<Writer.MergeState>();
+        for (IndexReader reader : readers) {
+          Reader r = reader.getIndexValues(fieldInfo.name);
+          if (r != null) {
+            mergeStates.add(new Writer.MergeState(r, docBase, reader
+                .maxDoc(), reader.getDeletedDocs()));
+          }
+          docBase += reader.numDocs();
+        }
+        if (mergeStates.isEmpty()) {
+          continue;
+        }
+        final String id = segment + "_" + fieldInfo.number;
+        final Writer writer;
+        switch (v) {
+        case PACKED_INTS:
+        case PACKED_INTS_FIXED:
+          writer = Ints.getWriter(directory, id, true);
+          break;
+        case SIMPLE_FLOAT_4BYTE:
+          writer = Floats.getWriter(directory, id, 4);
+          break;
+        case SIMPLE_FLOAT_8BYTE:
+          writer = Floats.getWriter(directory, id, 8);
+          break;
+        case BYTES_FIXED_STRAIGHT:
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.STRAIGHT, null, true);
+          break;
+        case BYTES_FIXED_DEREF:
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.DEREF, null, true);
+          break;
+        case BYTES_FIXED_SORTED:
+          // nocommit -- enable setting Comparator
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.SORTED, null, true);
+          break;
+        case BYTES_VAR_STRAIGHT:
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.STRAIGHT, null, false);
+          break;
+        case BYTES_VAR_DEREF:
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.DEREF, null, false);
+          break;
+        case BYTES_VAR_SORTED:
+          // nocommit -- enable setting Comparator
+          writer = Bytes.getWriter(directory, id,
+              Bytes.Mode.SORTED, null, false);
+          break;
+        default:
+          continue;
+        }
+        writer.add(mergeStates);
+        writer.finish(mergedDocs);
+      }
+    }
+  }
+
   private int copyFieldsWithDeletions(final FieldsWriter fieldsWriter, final IndexReader reader,
                                       final FieldsReader matchingFieldsReader)
     throws IOException, MergeAbortedException, CorruptIndexException {
