diff --git a/lucene/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/src/java/org/apache/lucene/index/IndexWriter.java
index 8817c76..aca12e5 100644
--- a/lucene/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/src/java/org/apache/lucene/index/IndexWriter.java
@@ -39,7 +39,9 @@ import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.index.DocumentsWriterPerThread.FlushedSegment;
 import org.apache.lucene.index.FieldInfos.FieldNumberBiMap;
+import org.apache.lucene.index.IOContext.Context;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.index.MergePolicy.OneMerge;
 import org.apache.lucene.index.PayloadProcessorProvider.DirPayloadProcessor;
 import org.apache.lucene.index.SegmentCodecs.SegmentCodecsBuilder;
 import org.apache.lucene.index.codecs.CodecProvider;
@@ -592,8 +594,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
      * enrolled in the pool, so you should simply close()
      * it when you're done (ie, do not call release()).
      */
-    public synchronized SegmentReader getReadOnlyClone(SegmentInfo info, boolean doOpenStores, int termInfosIndexDivisor) throws IOException {
-      SegmentReader sr = get(info, doOpenStores, BufferedIndexInput.BUFFER_SIZE, termInfosIndexDivisor);
+    public synchronized SegmentReader getReadOnlyClone(SegmentInfo info, boolean doOpenStores, int termInfosIndexDivisor, IOContext context) throws IOException {
+      SegmentReader sr = get(info, doOpenStores, context, termInfosIndexDivisor);
       try {
         return (SegmentReader) sr.clone(true);
       } finally {
@@ -609,8 +611,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
      * @param doOpenStores
      * @throws IOException
      */
-    public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores) throws IOException {
-      return get(info, doOpenStores, BufferedIndexInput.BUFFER_SIZE, config.getReaderTermsIndexDivisor());
+    public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores, IOContext context) throws IOException {
+      return get(info, doOpenStores, context, config.getReaderTermsIndexDivisor());
     }
 
     /**
@@ -624,18 +626,20 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
      * @param termsIndexDivisor
      * @throws IOException
      */
-    public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores, int readBufferSize, int termsIndexDivisor) throws IOException {
+    public synchronized SegmentReader get(SegmentInfo info, boolean doOpenStores, IOContext context, int termsIndexDivisor) throws IOException {
 
-      if (poolReaders) {
-        readBufferSize = BufferedIndexInput.BUFFER_SIZE;
-      }
+      //      if (poolReaders) {
+      //        readBufferSize = BufferedIndexInput.BUFFER_SIZE;
+      //      }
+      
+      // nocommit context should be part of the key used to cache that reader in the pool.
 
       SegmentReader sr = readerMap.get(info);
       if (sr == null) {
         // TODO: we may want to avoid doing this while
         // synchronized
         // Returns a ref, which we xfer to readerMap:
-        sr = SegmentReader.get(false, info.dir, info, readBufferSize, doOpenStores, termsIndexDivisor);
+        sr = SegmentReader.get(false, info.dir, info, doOpenStores, termsIndexDivisor, context);
         sr.readerFinishedListeners = readerFinishedListeners;
 
         if (info.dir == directory) {
@@ -2183,6 +2187,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
     SegmentInfo newSegment = flushedSegment.segmentInfo;
 
     setDiagnostics(newSegment, "flush");
+    
+    IOContext context = new IOContext(Context.FLUSH);
 
     boolean success = false;
     try {
@@ -2190,7 +2196,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, "", IndexFileNames.COMPOUND_FILE_EXTENSION);
         message("creating compound file " + compoundFileName);
         // Now build compound file
-        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);
+        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName, context);
         for(String fileName : newSegment.files()) {
           cfsWriter.addFile(fileName);
         }
@@ -2222,7 +2228,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
           // shortly-to-be-opened SegmentReader and let it
           // carry the changes; there's no reason to use
           // filesystem as intermediary here.
-          flushedSegment.deletedDocuments.write(directory, delFileName);
+          flushedSegment.deletedDocuments.write(directory, delFileName, context);
           success2 = true;
         } finally {
           if (!success2) {
@@ -2391,11 +2397,13 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
                 // optimize case only for segments that don't share doc stores
                 && versionComparator.compare(info.getVersion(), "3.1") >= 0;
           }
-
+          
+          IOContext context = new IOContext(new MergeInfo(info.docCount, info.sizeInBytes(true), true, false));
+          
           if (createCFS) {
-            copySegmentIntoCFS(info, newSegName);
+            copySegmentIntoCFS(info, newSegName, context);
           } else {
-            copySegmentAsIs(info, newSegName, dsNames, dsFilesCopied);
+            copySegmentAsIs(info, newSegName, dsNames, dsFilesCopied, context);
           }
 
           infos.add(info);
@@ -2454,7 +2462,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
 
       for (IndexReader reader : readers)      // add new indexes
         merger.add(reader);
-
+      // nocommit - we should pass a MergeInfo here into merge to create corresponding IOContext instances?
       int docCount = merger.merge();                // merge 'em
 
       final FieldInfos fieldInfos = merger.fieldInfos();
@@ -2475,7 +2483,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
 
       // Now create the compound file if needed
       if (useCompoundFile) {
-        merger.createCompoundFile(mergedName + ".cfs", info);
+        IOContext context = new IOContext(new MergeInfo(info.docCount, info.sizeInBytes(true), true, false));
+        merger.createCompoundFile(mergedName + ".cfs", info, context);
 
         // delete new non cfs files directly: they were never
         // registered with IFD
@@ -2499,10 +2508,10 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
   }
 
   /** Copies the segment into the IndexWriter's directory, as a compound segment. */
-  private void copySegmentIntoCFS(SegmentInfo info, String segName) throws IOException {
+  private void copySegmentIntoCFS(SegmentInfo info, String segName, IOContext context) throws IOException {
     String segFileName = IndexFileNames.segmentFileName(segName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);
     Collection<String> files = info.files();
-    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, segFileName);
+    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, segFileName, context);
     for (String file : files) {
       String newFileName = segName + IndexFileNames.stripSegmentName(file);
       if (!IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION)
@@ -2510,7 +2519,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         cfsWriter.addFile(file, info.dir);
       } else {
         assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
-        info.dir.copy(directory, file, newFileName);
+        info.dir.copy(directory, file, newFileName, context);
       }
     }
     
@@ -2524,7 +2533,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
   
   /** Copies the segment files as-is into the IndexWriter's directory. */
   private void copySegmentAsIs(SegmentInfo info, String segName,
-      Map<String, String> dsNames, Set<String> dsFilesCopied)
+      Map<String, String> dsNames, Set<String> dsFilesCopied, IOContext context)
       throws IOException {
     // Determine if the doc store of this segment needs to be copied. It's
     // only relevant for segments that share doc store with others,
@@ -2560,7 +2569,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       }
       
       assert !directory.fileExists(newFileName): "file \"" + newFileName + "\" already exists";
-      info.dir.copy(directory, file, newFileName);
+      info.dir.copy(directory, file, newFileName, context);
     }
     
     info.setDocStore(info.getDocStoreOffset(), newDsName, info.getDocStoreIsCompoundFile());
@@ -3416,6 +3425,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
     int mergedDocCount = 0;
 
     List<SegmentInfo> sourceSegments = merge.segments;
+    
+    IOContext context = new IOContext(merge.getMergeInfo());
 
     SegmentMerger merger = new SegmentMerger(directory, config.getTermIndexInterval(), mergedName, merge,
                                              payloadProcessorProvider, merge.info.getFieldInfos());
@@ -3439,7 +3450,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
         // Hold onto the "live" reader; we will use this to
         // commit merged deletes
         final SegmentReader reader = readerPool.get(info, true,
-                                                    MERGE_READ_BUFFER_SIZE,
+                                                    context,
                                                     -config.getReaderTermsIndexDivisor());
         merge.readers.add(reader);
 
@@ -3493,7 +3504,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
           if (infoStream != null) {
             message("create compound file " + compoundFileName);
           }
-          merger.createCompoundFile(compoundFileName, merge.info);
+          merger.createCompoundFile(compoundFileName, merge.info, new IOContext(merge.getMergeInfo()));
           success = true;
         } catch (IOException ioe) {
           synchronized(this) {
@@ -3563,7 +3574,9 @@ public class IndexWriter implements Closeable, TwoPhaseCommit {
       // keep deletes (it's costly to open entire reader
       // when we just need deletes)
 
-      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, BufferedIndexInput.BUFFER_SIZE, termsIndexDivisor);
+      // nocommit  should we use another flag "isMergedSegment" or a "READ" context here?
+      
+      final SegmentReader mergedReader = readerPool.get(merge.info, loadDocStores, context, termsIndexDivisor);
       try {
         if (poolReaders && mergedSegmentWarmer != null) {
           mergedSegmentWarmer.warm(mergedReader);
